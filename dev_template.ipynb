{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Callable\n",
    "import json\n",
    "import os\n",
    "import typing\n",
    "from typing import Awaitable\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import aiofiles\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langchain.chat_models.base import BaseChatModel\n",
    "from langchain import chat_models\n",
    "from pydantic import BaseModel, Field, RootModel\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201a7a2",
   "metadata": {},
   "source": [
    "### Define the shape of the profile an analyzer should return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5200c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Profile(BaseModel):\n",
    "    identity: float = Field(ge=0, le=1)\n",
    "\n",
    "    def cmp(self, other: \"Profile\") -> float:\n",
    "        return abs(self.identity - other.identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0701e7f",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProdProfile(BaseModel):\n",
    "    identity: float = Field(ge=0, le=1)\n",
    "    horoscope: str = Field()\n",
    "\n",
    "    def cmp(self, other: \"ProdProfile\") -> float:\n",
    "        return abs(self.identity - other.identity)\n",
    "\n",
    "\n",
    "class QuestionResponse(BaseModel):\n",
    "    question: str = Field()\n",
    "    response: str = Field()\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    first_name: str = Field()\n",
    "    last_name: str = Field()\n",
    "    responses: dict[str, QuestionResponse] = Field()\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    response: Response = Field()\n",
    "    prod_profile: ProdProfile | None = Field()\n",
    "\n",
    "\n",
    "UserSet = Annotated[dict[str, Response], Field()]\n",
    "\n",
    "Couple = Annotated[tuple[str, str], Field()]\n",
    "CouplePairs = Annotated[dict[str, Couple], Field()]\n",
    "\n",
    "\n",
    "Analyzer = Callable[[Response], Awaitable[Profile]]\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "\n",
    "if False:\n",
    "\n",
    "    def update_data():\n",
    "        from supabase.lib.client_options import SyncClientOptions\n",
    "        import supabase\n",
    "\n",
    "        from typing import Any\n",
    "\n",
    "        SUPABASE_URL_BASE = \"https://znsozdvrmfdwxyymtgdz.supabase.co/\"\n",
    "\n",
    "        with open(\"secrets.json\", \"r\") as f:\n",
    "            secrets = json.load(f)\n",
    "\n",
    "        sb_client = supabase.create_client(\n",
    "            SUPABASE_URL_BASE,\n",
    "            secrets[\"EEVA_SUPABASE_SERVICE_KEY\"],\n",
    "            options=SyncClientOptions(auto_refresh_token=False, persist_session=False),\n",
    "        )\n",
    "\n",
    "        questions = sb_client.table(\"questions\").select(\"*\").execute().data\n",
    "        raw_answers = (\n",
    "            sb_client.table(\"user_answers\")\n",
    "            .select(\"user_id, question_id, answer_text\")\n",
    "            .execute()\n",
    "            .data\n",
    "        )\n",
    "        user_answer_lists: dict[str, dict[str, str]] = {}\n",
    "        for ans in raw_answers:\n",
    "            user_answer_lists.setdefault(ans[\"user_id\"], {})[ans[\"question_id\"]] = ans[\n",
    "                \"answer_text\"\n",
    "            ]\n",
    "\n",
    "        raw_user_data = (\n",
    "            sb_client.table(\"profiles\")\n",
    "            .select(\"user_id,first_name,last_name,hidden,profile\")\n",
    "            .execute()\n",
    "            .data\n",
    "        )\n",
    "        users: dict[str, dict[str, Any]] = {}\n",
    "        for user in raw_user_data:\n",
    "            user_id = user[\"user_id\"]\n",
    "            if user[\"hidden\"] or user_id not in user_answer_lists:\n",
    "                continue\n",
    "            users[user_id] = {\n",
    "                \"first_name\": user[\"first_name\"],\n",
    "                \"last_name\": user[\"last_name\"],\n",
    "                \"profile\": ProdProfile.model_validate(user[\"profile\"])\n",
    "                if user[\"profile\"]\n",
    "                else None,\n",
    "                \"answers\": user_answer_lists[user_id],\n",
    "            }\n",
    "\n",
    "        user_data: dict[str, User] = {}\n",
    "        # Build a lookup for question text\n",
    "        question_text_lookup = {q[\"id\"]: q[\"text\"] for q in questions}\n",
    "        for user_id, user in users.items():\n",
    "            answers = user[\"answers\"]\n",
    "            responses = {}\n",
    "            for question_id, answer_text in answers.items():\n",
    "                question_text = question_text_lookup.get(question_id, \"\")\n",
    "                responses[question_id] = {\n",
    "                    \"question\": question_text,\n",
    "                    \"response\": answer_text,\n",
    "                }\n",
    "            response = Response(\n",
    "                first_name=user[\"first_name\"],\n",
    "                last_name=user[\"last_name\"] if user[\"last_name\"] else \"\",\n",
    "                responses=responses,\n",
    "            )\n",
    "            user_data[user_id] = User(\n",
    "                response=response,\n",
    "                prod_profile=user[\"profile\"],\n",
    "            )\n",
    "\n",
    "        with open(DATA_DIR / \"user_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(\n",
    "                {k: v.model_dump() for k, v in user_data.items()},\n",
    "                f,\n",
    "                indent=2,\n",
    "            )\n",
    "\n",
    "    update_data()\n",
    "\n",
    "with open(\"secrets.json\", \"r\") as f:\n",
    "    secrets = json.load(f)\n",
    "    os.environ[\"OPENAI_API_KEY\"] = secrets[\"OPENAI_API_KEY\"]\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = secrets[\"ANTHROPIC_API_KEY\"]\n",
    "\n",
    "# llm = chat_models.init_chat_model(\"gpt-4.1-nano\", model_provider=\"openai\")\n",
    "# llm = chat_models.init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "# llm = chat_models.init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "# llm = chat_models.init_chat_model(\"gpt-5\", model_provider=\"openai\")\n",
    "# llm = chat_models.init_chat_model(\"gpt-5-mini\", model_provider=\"openai\")\n",
    "llm = chat_models.init_chat_model(\"gpt-5-nano\", model_provider=\"openai\")\n",
    "# llm = chat_models.init_chat_model(\"claude-3-5-haiku-latest\", model_provider=\"anthropic\")\n",
    "# llm = chat_models.init_chat_model(\"claude-sonnet-4-20250514\", model_provider=\"anthropic\")\n",
    "\n",
    "with open(DATA_DIR / \"user_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    class UserSetDeserializer(RootModel[dict[str, User]]):\n",
    "        pass\n",
    "\n",
    "    user_data = UserSetDeserializer.model_validate_json(f.read()).root\n",
    "\n",
    "with open(DATA_DIR / \"couples.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    couple_pairs_raw: dict[str, list[str]] = json.load(f)\n",
    "    couple_pairs: dict[str, Couple] = {\n",
    "        k: (v[0], v[1]) for k, v in couple_pairs_raw.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3888568d",
   "metadata": {},
   "source": [
    "## Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e4a6b",
   "metadata": {},
   "source": [
    "### Define analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e15aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze(response: Response, llm: BaseChatModel, data_path: Path) -> Profile:\n",
    "    async with aiofiles.open(\n",
    "        data_path / \"identity.txt\", mode=\"r\", encoding=\"utf-8\"\n",
    "    ) as f:\n",
    "        identity_prompt = await f.read()\n",
    "\n",
    "    class AnalyzerOutput(BaseModel):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "        identity: float = Field(ge=0, le=1, description=identity_prompt)\n",
    "\n",
    "    structured_llm = llm.with_structured_output(AnalyzerOutput)\n",
    "\n",
    "    content = \"\\n\".join(\n",
    "        f\"{question}: {question_response.response}\"\n",
    "        for question, question_response in response.responses.items()\n",
    "    )\n",
    "\n",
    "    raw_output = await structured_llm.ainvoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Please analyze the identity of this set of answers.\"\n",
    "            ),\n",
    "            HumanMessage(content=content),\n",
    "        ]\n",
    "    )\n",
    "    if isinstance(raw_output, dict):\n",
    "        output = AnalyzerOutput(**raw_output)\n",
    "    elif isinstance(raw_output, AnalyzerOutput):\n",
    "        output = typing.cast(AnalyzerOutput, raw_output)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unexpected output type: {type(raw_output)}. Expected dict or AnalyzerOutput.\"\n",
    "        )\n",
    "    avg_identity = output.identity\n",
    "    profile = Profile(identity=avg_identity)\n",
    "\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56efab93",
   "metadata": {},
   "source": [
    "### Calculate profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_user_profiles(\n",
    "    user_id: str, user: User, num_profiles: int\n",
    ") -> tuple[str, list[Profile]]:\n",
    "    tasks = []\n",
    "    for _ in range(num_profiles):\n",
    "        tasks.append(asyncio.create_task(analyze(user.response, llm, DATA_DIR)))\n",
    "    return user_id, await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "# Create a dict user_id -> Profile for all users in user_data using their responses to run `analyze`\n",
    "# Use asyncio to run analyze concurrently for all users\n",
    "async def generate_profiles(\n",
    "    user_data: dict[str, User], num_profiles: int, user_subset: set[str] | None\n",
    ") -> dict[str, list[Profile]]:\n",
    "    if user_subset is not None:\n",
    "        user_data = {k: v for k, v in user_data.items() if k in user_subset}\n",
    "\n",
    "    profiles: dict[str, Profile] = {}\n",
    "\n",
    "    async def analyze_all_users():\n",
    "        tasks = []\n",
    "        for user_id, user in user_data.items():\n",
    "            tasks.append(\n",
    "                asyncio.create_task(generate_user_profiles(user_id, user, num_profiles))\n",
    "            )\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        for user_id, user_profiles in results:\n",
    "            profiles[user_id] = user_profiles\n",
    "\n",
    "    await analyze_all_users()\n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ebeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TESTS = 5\n",
    "\n",
    "profiles = await generate_profiles(user_data, NUM_TESTS, None)\n",
    "profile_list = [(id, profile) for id, profile in profiles.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9533eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, pair in couple_pairs.items():\n",
    "    user1_scores = [profile.identity for profile in profiles[pair[0]]]\n",
    "    user2_scores = [profile.identity for profile in profiles[pair[1]]]\n",
    "    print(f\"{key}: {user1_scores} - {user2_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e2ccb",
   "metadata": {},
   "source": [
    "### Test analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b658ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(\n",
    "    [\n",
    "        [profile.identity for profile in user_profiles]\n",
    "        for _id, user_profiles in profile_list\n",
    "    ]\n",
    ").T\n",
    "couple_indices_list = []\n",
    "for id1, id2 in couple_pairs.values():\n",
    "    idx1 = None\n",
    "    idx2 = None\n",
    "    for idx, (id, _profile) in enumerate(profile_list):\n",
    "        if id == id1:\n",
    "            idx1 = idx\n",
    "        if id == id2:\n",
    "            idx2 = idx\n",
    "    if idx1 is not None and idx2 is not None:\n",
    "        couple_indices_list.append([idx1, idx2])\n",
    "\n",
    "couple_indices = np.array(couple_indices_list)\n",
    "print(f\"Values shape: {values.shape}\")\n",
    "print(f\"Couple indices shape: {couple_indices.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea40d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "couple_values = values[:, couple_indices]\n",
    "print(f\"Couple values shape: {couple_values.shape}\")\n",
    "couple_scores = np.abs(couple_values[:, :, 0] - couple_values[:, :, 1])\n",
    "print(f\"Couple scores shape: {couple_scores.shape}\")\n",
    "avg_couple_score = np.mean(couple_scores, axis=1)\n",
    "print(f\"Avg couple score shape: {avg_couple_score.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b62a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_couples(num_users: int, num_random_couples: int, rng):\n",
    "    return rng.sample(range(num_users), 2 * num_random_couples)\n",
    "\n",
    "\n",
    "def gen_random_couple_sets(num_users: int, num_random_couples: int, num_sets: int, rng):\n",
    "    return np.array(\n",
    "        [\n",
    "            gen_random_couples(num_users, num_random_couples, rng)\n",
    "            for _ in range(num_sets)\n",
    "        ]\n",
    "    ).reshape(num_sets, num_random_couples, 2)\n",
    "\n",
    "\n",
    "rng = Random(45)\n",
    "random_couple_sets = gen_random_couple_sets(\n",
    "    values.shape[1], len(couple_pairs), 100_000, rng\n",
    ")\n",
    "print(random_couple_sets.shape)\n",
    "random_couple_scores = np.abs(\n",
    "    values[:, random_couple_sets[:, :, 0]] - values[:, random_couple_sets[:, :, 1]]\n",
    ")\n",
    "print(random_couple_scores.shape)\n",
    "random_avgs = random_couple_scores.mean(axis=2)\n",
    "print(random_avgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba20b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_square = np.abs(values[:, :, None] - values[:, None, :])\n",
    "scores_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each member of a couple, the number of users with closer identity than their partner.\n",
    "# Subtract 2 to exclude themselves and their partner.\n",
    "print(scores_square[:, couple_indices].shape)\n",
    "steps_to_partner = (\n",
    "    np.sum(scores_square[:, couple_indices] <= couple_scores[:, :, None, None], axis=3)\n",
    "    - 2\n",
    ")\n",
    "print(steps_to_partner.shape)\n",
    "avg_steps_to_partner = np.mean(steps_to_partner, axis=(1, 2))\n",
    "print(avg_steps_to_partner.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93210cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_steps_to_partner = (\n",
    "    np.sum(\n",
    "        scores_square[:, random_couple_sets]\n",
    "        <= random_couple_scores[:, :, :, None, None],\n",
    "        axis=4,\n",
    "    )\n",
    "    - 2\n",
    ")\n",
    "random_avg_steps_to_partner = np.mean(random_steps_to_partner, axis=(2, 3))\n",
    "random_avg_steps_to_partner\n",
    "print(random_avg_steps_to_partner.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb25f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, NUM_TESTS, figsize=(20, 9))\n",
    "for i in range(NUM_TESTS):\n",
    "    ax = axs[0, i]\n",
    "    ax.hist(random_avgs[i], bins=50, color=\"skyblue\", edgecolor=\"black\")\n",
    "    ax.axvline(\n",
    "        avg_couple_score[i],\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=f\"Observed avg = {avg_couple_score[i]:.3f}\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Average |Δ identity|\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(\"Distribution of Avg |Δ identity| (random samples)\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax = axs[1, i]\n",
    "    ax.hist(\n",
    "        random_avg_steps_to_partner[i], bins=50, color=\"lightgreen\", edgecolor=\"black\"\n",
    "    )\n",
    "    ax.axvline(\n",
    "        avg_steps_to_partner[i],\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=f\"Observed avg = {avg_steps_to_partner[i]:.3f}\",\n",
    "    )\n",
    "    ax.axvline(\n",
    "        np.mean(random_avg_steps_to_partner[i]),\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=f\"Observed avg = {np.mean(random_avg_steps_to_partner[i]):.3f}\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Average steps to partner\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(\"Distribution of Avg steps to partner (random samples)\")\n",
    "    ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "identity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
