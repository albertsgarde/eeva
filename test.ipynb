{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain import chat_models\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = json.load(open(\"secrets.json\"))\n",
    "for key, value in secrets.items():\n",
    "    os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message:\n",
    "    role_id: int\n",
    "    content: str\n",
    "\n",
    "    def __init__(self, role_id: int, content: str):\n",
    "        self.role_id = role_id\n",
    "        self.content = content\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Message(role_id={self.role_id}, content={self.content})\"\n",
    "\n",
    "    def to_human_message(self) -> HumanMessage:\n",
    "        return HumanMessage(content=self.content)\n",
    "\n",
    "    def to_message(self, cur_role: int) -> BaseMessage:\n",
    "        if cur_role == self.role_id:\n",
    "            return self.to_human_message()\n",
    "        else:\n",
    "            return self.to_human_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Role:\n",
    "    id: int\n",
    "    system_message: str\n",
    "    model: BaseChatModel\n",
    "\n",
    "    def __init__(self, id: int, system_message: str, model: BaseChatModel):\n",
    "        self.id = id\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "\n",
    "    def create_history(self, messages: Sequence[Message]) -> Sequence[BaseMessage]:\n",
    "        return [SystemMessage(content=self.system_message)] + [\n",
    "            message.to_message(self.id) for message in messages\n",
    "        ]\n",
    "\n",
    "    def advance(self, messages: Sequence[Message]) -> Message:\n",
    "        history = self.create_history(messages)\n",
    "        response = self.model.invoke(history)\n",
    "        if isinstance(response.content, str):\n",
    "            return Message(self.id, response.content)\n",
    "        else:\n",
    "            raise Exception(\"Multiple responses received\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "role0_system_prompt = (\n",
    "    \"You are in a conversation with a friend you have a slight crush on\"\n",
    ")\n",
    "role1_system_prompt = (\n",
    "    \"You are in a conversation with a friend you need to ask for money\"\n",
    ")\n",
    "role0_start_message = \"How are you doing?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = chat_models.init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "role0: Role\n",
    "role1: Role\n",
    "messages: list[Message]\n",
    "\n",
    "\n",
    "def reset():\n",
    "    global role0, role1, messages\n",
    "    role0 = Role(0, role0_system_prompt, model)\n",
    "    role1 = Role(1, role1_system_prompt, model)\n",
    "    messages = [Message(0, \"How are you doing?\")]\n",
    "\n",
    "\n",
    "def advance():\n",
    "    global messages, role0, role1\n",
    "    prev_role = messages[-1].role_id\n",
    "    if prev_role == 0:\n",
    "        response = role1.advance(messages)\n",
    "        messages += [response]\n",
    "    else:\n",
    "        response = role0.advance(messages)\n",
    "        messages += [response]\n",
    "    for message in messages:\n",
    "        print(f\"{message.role_id}: {message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
