{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain import chat_models\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = json.load(open(\"secrets.json\"))\n",
    "for key, value in secrets.items():\n",
    "    os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    role_id: int = Field()\n",
    "    content: str = Field()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Message(role_id={self.role_id}, content={self.content})\"\n",
    "\n",
    "    def to_human_message(self) -> HumanMessage:\n",
    "        return HumanMessage(content=self.content)\n",
    "\n",
    "    def to_message(self, cur_role: int) -> BaseMessage:\n",
    "        if cur_role == self.role_id:\n",
    "            return self.to_human_message()\n",
    "        else:\n",
    "            return self.to_human_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Role(BaseModel):\n",
    "    id: int = Field()\n",
    "    system_message: str = Field()\n",
    "    model: BaseChatModel = Field()\n",
    "\n",
    "    def create_history(self, messages: Sequence[Message]) -> Sequence[BaseMessage]:\n",
    "        return [SystemMessage(content=self.system_message)] + [\n",
    "            message.to_message(self.id) for message in messages\n",
    "        ]\n",
    "\n",
    "    def advance(self, messages: Sequence[Message]) -> Message:\n",
    "        history = self.create_history(messages)\n",
    "        response = self.model.invoke(history)\n",
    "        if isinstance(response.content, str):\n",
    "            return Message(role_id=self.id, content=response.content)\n",
    "        else:\n",
    "            raise Exception(\"Multiple responses received\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationConfig:\n",
    "    role0_system_prompt: str\n",
    "    role1_system_prompt: str\n",
    "    role0_start_message: str\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        role0_system_prompt: str,\n",
    "        role1_system_prompt: str,\n",
    "        role0_start_message: str,\n",
    "    ):\n",
    "        self.role0_system_prompt = role0_system_prompt\n",
    "        self.role1_system_prompt = role1_system_prompt\n",
    "        self.role0_start_message = role0_start_message\n",
    "\n",
    "    def create_conversation(self) -> \"Conversation\":\n",
    "        return Conversation.initialize(self)\n",
    "\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    role0: Role = Field()\n",
    "    role1: Role = Field()\n",
    "    messages: list[Message] = Field()\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize(\n",
    "        config: ConversationConfig,\n",
    "    ) -> \"Conversation\":\n",
    "        role0 = Role(\n",
    "            id=0,\n",
    "            system_message=config.role0_system_prompt,\n",
    "            model=chat_models.init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\"),\n",
    "        )\n",
    "        role1 = Role(\n",
    "            id=1,\n",
    "            system_message=config.role1_system_prompt,\n",
    "            model=chat_models.init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\"),\n",
    "        )\n",
    "        messages = [Message(role_id=0, content=config.role0_start_message)]\n",
    "        return Conversation(role0=role0, role1=role1, messages=messages)\n",
    "\n",
    "    def advance(self, num_steps: int = 1) -> \"Conversation\":\n",
    "        for _ in range(num_steps):\n",
    "            if self.messages[-1].role_id == self.role0.id:\n",
    "                message = self.role1.advance(self.messages)\n",
    "            else:\n",
    "                message = self.role0.advance(self.messages)\n",
    "            self.messages.append(message)\n",
    "        return self\n",
    "\n",
    "    def get_messages(self) -> Sequence[Message]:\n",
    "        return self.messages\n",
    "\n",
    "    def print_messages(self) -> None:\n",
    "        for message in self.messages:\n",
    "            print(f\"{message.role_id}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "role0_system_prompt = (\n",
    "    \"You are in a conversation with a friend you have a slight crush on\"\n",
    ")\n",
    "role1_system_prompt = (\n",
    "    \"You are in a conversation with a friend you need to ask for money\"\n",
    ")\n",
    "role0_start_message = \"How are you doing?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConversationConfig(\n",
    "    role0_system_prompt=role0_system_prompt,\n",
    "    role1_system_prompt=role1_system_prompt,\n",
    "    role0_start_message=role0_start_message,\n",
    ")\n",
    "conversation = config.create_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = config.create_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: How are you doing?\n",
      "1: I'm doing well, thanks! How about you? It's been a while since we caught up.\n",
      "0: I know, right? I’ve missed our chats! I’ve been doing pretty well, just keeping busy with work and some personal projects. What about you? Anything exciting happening in your life?\n",
      "1: It's great to hear you've been keeping busy! I've been focused on a few things too, but to be honest, I've hit a bit of a rough patch financially lately. I'm looking for some help to get through it. Would it be possible for you to lend me a little money? I’d really appreciate it!\n",
      "0: I'm really sorry to hear that you’re going through a rough patch. I wish I could help you out more directly. Is there anything else I could do to support you? Maybe we can brainstorm some ideas together?\n",
      "1: I totally understand, and I appreciate your willingness to help in other ways! If you have any ideas or resources that could assist in getting through this situation, I’m all ears. Just having someone to talk to about it makes a difference, so thank you for that.\n"
     ]
    }
   ],
   "source": [
    "conversation.advance(5)\n",
    "conversation.print_messages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
